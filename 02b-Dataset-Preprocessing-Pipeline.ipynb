{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Ordinal-Encoding\" data-toc-modified-id=\"Ordinal-Encoding-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Ordinal Encoding</a></span></li><li><span><a href=\"#OneHot-Encoding-of-categorical-features\" data-toc-modified-id=\"OneHot-Encoding-of-categorical-features-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>OneHot Encoding of categorical features</a></span></li><li><span><a href=\"#Numerical-columns\" data-toc-modified-id=\"Numerical-columns-0.3\"><span class=\"toc-item-num\">0.3&nbsp;&nbsp;</span>Numerical columns</a></span><ul class=\"toc-item\"><li><span><a href=\"#Surface-Area\" data-toc-modified-id=\"Surface-Area-0.3.1\"><span class=\"toc-item-num\">0.3.1&nbsp;&nbsp;</span>Surface Area</a></span></li></ul></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-0.4\"><span class=\"toc-item-num\">0.4&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Removing-outliers\" data-toc-modified-id=\"Removing-outliers-0.5\"><span class=\"toc-item-num\">0.5&nbsp;&nbsp;</span>Removing outliers</a></span></li><li><span><a href=\"#Output-processing\" data-toc-modified-id=\"Output-processing-0.6\"><span class=\"toc-item-num\">0.6&nbsp;&nbsp;</span>Output processing</a></span></li><li><span><a href=\"#XGBoost-model\" data-toc-modified-id=\"XGBoost-model-0.7\"><span class=\"toc-item-num\">0.7&nbsp;&nbsp;</span>XGBoost model</a></span></li></ul></li><li><span><a href=\"#Model-training\" data-toc-modified-id=\"Model-training-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Model training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Gridsearch-hyperparameters-estimation\" data-toc-modified-id=\"Gridsearch-hyperparameters-estimation-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Gridsearch hyperparameters estimation</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Training</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluation-on-the-training-set\" data-toc-modified-id=\"Evaluation-on-the-training-set-1.3.1\"><span class=\"toc-item-num\">1.3.1&nbsp;&nbsp;</span>Evaluation on the training set</a></span></li><li><span><a href=\"#Evaluation-on-the-validation-set\" data-toc-modified-id=\"Evaluation-on-the-validation-set-1.3.2\"><span class=\"toc-item-num\">1.3.2&nbsp;&nbsp;</span>Evaluation on the validation set</a></span></li></ul></li><li><span><a href=\"#Test\" data-toc-modified-id=\"Test-1.4\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Test</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame, read_csv, concat, get_dummies, Series, CategoricalDtype\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.preprocessing import (normalize, StandardScaler, LabelEncoder,\n",
    "                                   OneHotEncoder, OrdinalEncoder, FunctionTransformer,\n",
    "                                   PowerTransformer)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline, TransformerMixin\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, TransformedTargetRegressor\n",
    "from sklearn.base import BaseEstimator\n",
    "import xgboost\n",
    "from xgboost import plot_importance, XGBRegressor\n",
    "from pprint import pprint\n",
    "from json import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'house-prices'\n",
    "version='v0.1-pipe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrain=read_csv('./train.csv',index_col=0)\n",
    "test=read_csv('./test.csv',index_col=0)\n",
    "fixed_seed=12345"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column='SalePrice'\n",
    "X_fulltrain = fulltrain.drop(target_column, axis=1)\n",
    "y_fulltrain = fulltrain[target_column]\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_fulltrain, y_fulltrain, test_size=0.2, random_state=fixed_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = load(open('categories.json',\"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_columns = [c for c in X_train.columns if c not in categories.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals={}\n",
    "for key, value in list(categories.items()):\n",
    "    if value[0] == 'Ex':\n",
    "        ordinals[key] = value\n",
    "        categories.pop(key)\n",
    "for col, tags in ordinals.items():\n",
    "    tags.reverse()\n",
    "    \n",
    "ord_columns = list(ordinals.keys())\n",
    "ord_values = list(ordinals.values())\n",
    "cat_columns = list(categories.keys())\n",
    "cat_values = list(categories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinals.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for col in ord_columns:\n",
    "#     print(X_train[col].unique())\n",
    "# for col in cat_columns:\n",
    "#     print(X_train[col].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from scipy.stats import norm\n",
    "    \n",
    "EPSILON = 0.001\n",
    "    \n",
    "class GaussianOrdinals(TransformerMixin, BaseEstimator):\n",
    "    def fit(self, X, y=None):\n",
    "        self.quantiles = []\n",
    "        for col in range(X.shape[1]):\n",
    "            self.quantiles.append([])\n",
    "            maximum = int(np.max(X[:,col]))\n",
    "            value,count = np.unique(X[:,col], return_counts=True)\n",
    "            counts = dict(zip(value.astype(int),count))\n",
    "            prev_count = 0\n",
    "            for i in range(maximum+1):\n",
    "                count = prev_count + counts.get(i,0)\n",
    "                self.quantiles[col].append((prev_count + count)/(2*X.shape[0]))\n",
    "                # print(i, count, self.quantiles[col][i])\n",
    "                prev_count = count\n",
    "            if self.quantiles[col][0] < EPSILON:\n",
    "                self.quantiles[col][0] = EPSILON\n",
    "            if self.quantiles[col][-1] > 1 - EPSILON:\n",
    "                self.quantiles[col][-1] = 1 - EPSILON   \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        Xout = X.copy()\n",
    "        for col in range(X.shape[1]):\n",
    "            if np.max(X[:,col]) >= len(self.quantiles[col]):\n",
    "                print(np.max(X[:,col]))\n",
    "            for value,quantile in enumerate(self.quantiles[col]):\n",
    "                Xout[:,col][(X[:,col])==value] = norm.ppf(quantile)\n",
    "        return Xout\n",
    "            \n",
    "    \n",
    "#    def inverse_transform(self, X):\n",
    "#        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OrdinalEncoder(categories=ord_values)),\n",
    "#    ('gauss', PowerTransformer())\n",
    "    ('gauss', GaussianOrdinals())\n",
    "#    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pipe = ColumnTransformer([\n",
    "    ('ord', ordinal_pipe, ord_columns)\n",
    "])\n",
    "test_pipe.transformers[0][1].steps[2] = ('scaler', StandardScaler())\n",
    "X1 = test_pipe.fit_transform(X_train)\n",
    "test_pipe.transformers[0][1].steps[2] = ('gauss', PowerTransformer())\n",
    "X2 = test_pipe.fit_transform(X_train)\n",
    "test_pipe.transformers[0][1].steps[2] = ('gauss', GaussianOrdinals())\n",
    "X3 = test_pipe.fit_transform(X_train)\n",
    "\n",
    "plt.figure(figsize=(18,8))\n",
    "plt.subplot(3,1,1)\n",
    "sns.distplot(DataFrame(X1[:,4]), hist=True, kde_kws={'bw':0.5})\n",
    "plt.subplot(3,1,2)\n",
    "sns.distplot(DataFrame(X2[:,4]), hist=True, kde_kws={'bw':0.5})\n",
    "plt.subplot(3,1,3)\n",
    "sns.distplot(DataFrame(X3[:,4]), hist=True, kde_kws={'bw':0.5})\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OneHot Encoding of categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_pipe = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "#    ('imputer', SimpleImputer(strategy='constant', fill_value='NA')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Surface Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddSurface(TransformerMixin, BaseEstimator):\n",
    "    #def __init__(self):\n",
    "    #    pass\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X['Surface'] =  X['2ndFlrSF'] + X['1stFlrSF'] + X['TotalBsmtSF']\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipe = Pipeline([\n",
    "    ('surface', AddSurface()),\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_pipe = ColumnTransformer([\n",
    "    ('cat', categorical_pipe, cat_columns),\n",
    "    ('num', numeric_pipe, num_columns),\n",
    "    ('ord', ordinal_pipe, ord_columns)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutlierRemoverComposer(TransformerMixin, BaseEstimator):\n",
    "    def __init__(self, model, outlier_estimator, **kwargs):\n",
    "        self.outlier_estimator = outlier_estimator\n",
    "        self.model = model\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        outliers = self.outlier_estimator.fit_predict(X)\n",
    "        mask = outliers == 1\n",
    "\n",
    "        X_clean = X[mask]\n",
    "        y_clean = y[mask]\n",
    "        \n",
    "        self.model.fit(X_clean, y_clean)\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def predict(self,X, y=None):\n",
    "        return self.model.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_detection = Pipeline([\n",
    "    ('pp', preprocess_pipe),\n",
    "    ('outlier', IsolationForest(max_samples=100, random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_pipe = Pipeline([\n",
    "    ('log', FunctionTransformer(func=np.log, inverse_func=np.exp)),\n",
    "    ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(booster=\"gbtree\",colsample_bytree=0.9,\n",
    "                     max_depth=4, n_estimators=400, gamma= 0.01,\n",
    "                     min_child_weight=8,\n",
    "                     subsample=0.3,\n",
    "                     random_state=fixed_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipe = Pipeline([\n",
    "    ('pp', preprocess_pipe),\n",
    "    ('xgb', model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipe = TransformedTargetRegressor(regressor=model_pipe, transformer=output_pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_pipe = OutlierRemoverComposer(model=full_pipe, outlier_estimator=outlier_detection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = outlier_pipe\n",
    "#pipe = full_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gridsearch hyperparameters estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from hypopt import GridSearch\n",
    "# params = {'min_child_weight':[6,7,8,9], 'gamma':[i/100.0 for i in range(1,5)],  'subsample':[i/10.0 for i in range(2,5)],\n",
    "# 'colsample_bytree':[i/10.0 for i in range(8,10)], 'max_depth': [3,4,5]}\n",
    "\n",
    "# model = XGBRegressor(booster=\"gbtree\")\n",
    "# grid = GridSearch(model, params)\n",
    "# grid.fit(X_train, y_train, X_val, y_val)\n",
    "# grid.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RMSLE(y_true, y_pred):\n",
    "    return sqrt(mean_squared_error(np.log(y_true), np.log(y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_train)\n",
    "#y_pred = output_pipe.inverse_transform(y_pred_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = RMSLE(y_train, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.distplot(y_pred-y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe.predict(X_val)\n",
    "#y_pred = output_pipe.inverse_transform(y_pred_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = RMSLE(y_val, y_pred)\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "sns.distplot(y_pred-y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pipe.predict(test)\n",
    "#test_pred = output_pipe.inverse_transform(test_pred_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = DataFrame({\"SalePrice\": test_pred}, index=test.index)\n",
    "submission.to_csv('test-prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_process.to_csv('X_train.csv')\n",
    "# X_val.to_csv('X_val.csv')\n",
    "# test.to_csv('X_test.csv')\n",
    "# y_train_clean.to_csv('y_train.csv', header=True)\n",
    "# y_val.to_csv('y_val.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
