{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame, read_csv, Series\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from numpy import transpose\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.optimizers import SGD,RMSprop,Adam\n",
    "from time import time\n",
    "import seaborn as sns\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "\n",
    "#a = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "#b = tf.constant([[1.0, 2.0], [3.0, 4.0], [5.0, 6.0]])\n",
    "#c = tf.matmul(a, b)\n",
    "\n",
    "#print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log = read_csv('X_train.csv', index_col=0)\n",
    "X_val_log = read_csv('X_val.csv', index_col=0)\n",
    "test_log = read_csv('X_test.csv', index_col=0)\n",
    "y_train_log = read_csv('y_train.csv', index_col=0)\n",
    "y_val_log = read_csv('y_val.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_log.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_log.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_Y = StandardScaler()\n",
    "scaler_Y.fit(y_train_log)\n",
    "\n",
    "y_train = scaler_Y.transform(y_train_log)\n",
    "y_val = scaler_Y.transform(y_val_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_log.values.astype(float)\n",
    "X_val = X_val_log.values.astype(float)\n",
    "test = test_log.values.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select n best features according to XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_features = 75 # 24\n",
    "X_train = X_train[:,:nb_features]\n",
    "X_val = X_val[:,:nb_features]\n",
    "test = test[:,:nb_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.backend import sigmoid, tanh, maximum\n",
    "def custom(x):\n",
    "    return maximum(x,tanh(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle de regression linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reg_model():\n",
    "    return Sequential([\n",
    "                    Input(shape=X_train.shape[1]),\n",
    "                    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modèle avec couches cachées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_other_model(nb_neurons=32):\n",
    "    return Sequential([\n",
    "                    Input(shape=X_train.shape[1]),\n",
    "                    Dense(nb_neurons, kernel_regularizer=regularizers.l1(0.001)),\n",
    "                    Activation('tanh', activity_regularizer=regularizers.l1(0.001)),\n",
    "#                    Dense(32, kernel_regularizer=regularizers.l1(0.001)),\n",
    "#                    Activation('tanh', activity_regularizer=regularizers.l1(0.001)),\n",
    "                    Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modèle simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'mse'\n",
    "LEARNING_RATE = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_reg_model()\n",
    "model.compile(loss=loss, optimizer=SGD(lr=LEARNING_RATE))\n",
    "BATCH_SIZE = X_train.shape[0] # computing the loss over the whole dataset\n",
    "EPOCHS = 750 # how many iterations over the whole dataset\n",
    "t_0 = time()\n",
    "#with tf.device('/device:GPU:0'):\n",
    "history = model.fit(X_train, y_train,  validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "\n",
    "print(time()-t_0, 's')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(history.history).plot(figsize=(8, 5), logy=True)\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.title('Model performance throughout training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_scaled = model.predict(X_val)\n",
    "y_p_scaled = y_p_scaled.reshape(y_p_scaled.shape[0])\n",
    "\n",
    "y_p_val = scaler_Y.inverse_transform(y_p_scaled)\n",
    "\n",
    "RMSLE = sqrt(mean_squared_error(y_val_log,y_p_val))\n",
    "print('Validation RMSLE:', RMSLE)\n",
    "y_p_scaled = model.predict(X_train)\n",
    "y_p_scaled = y_p_scaled.reshape(y_p_scaled.shape[0])\n",
    "\n",
    "y_p_train = scaler_Y.inverse_transform(y_p_scaled)\n",
    "\n",
    "RMSLE = sqrt(mean_squared_error(y_train_log.SalePrice,y_p_train))\n",
    "print('Train RMSLE:', RMSLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(y_p_train-y_train_log.SalePrice, axlabel='error on training set')\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(y_p_val-y_val_log.SalePrice, axlabel='error on validation set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_log_scaled = model.predict(test)\n",
    "test_pred_log = scaler_Y.inverse_transform(test_pred_log_scaled)\n",
    "test_pred = np.exp(test_pred_log).reshape(test_pred_log.shape[0])\n",
    "submission = DataFrame({\"SalePrice\": test_pred}, index=test_log.index)\n",
    "submission.to_csv('test-prediction-keras-lin.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hidden Layer Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_other_model()\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE=0.05\n",
    "model2.compile(loss=loss, optimizer=SGD(lr=LEARNING_RATE))\n",
    "#model.compile(loss=loss, optimizer=RMSprop(lr=LEARNING_RATE))\n",
    "#model.compile(loss=loss, optimizer=Adam(lr=LEARNING_RATE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = X_train.shape[0] # computing the loss over the whole dataset\n",
    "EPOCHS = 1000 # how many iterations over the whole dataset\n",
    "t_0 = time()\n",
    "#with tf.device('/device:GPU:0'):\n",
    "history = model2.fit(X_train, y_train, validation_data=(X_val, y_val), epochs=EPOCHS, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(time()-t_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrame(history.history).plot(figsize=(8, 5), logy=True)\n",
    "plt.grid(True)\n",
    "#plt.gca().set_ylim(0, 1)\n",
    "plt.title('Model performance throughout training')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p_scaled = model2.predict(X_val)\n",
    "y_p_scaled = y_p_scaled.reshape(y_p_scaled.shape[0])\n",
    "y_p_val = scaler_Y.inverse_transform(y_p_scaled)\n",
    "\n",
    "RMSLE = sqrt(mean_squared_error(y_val_log,y_p_val))\n",
    "print('Validation RMSLE:', RMSLE)\n",
    "y_p_scaled = model2.predict(X_train)\n",
    "y_p_scaled = y_p_scaled.reshape(y_p_scaled.shape[0])\n",
    "\n",
    "y_p_train = scaler_Y.inverse_transform(y_p_scaled)\n",
    "\n",
    "RMSLE = sqrt(mean_squared_error(y_train_log.SalePrice, y_p_train))\n",
    "print('Train RMSLE:', RMSLE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.subplot(1,2,1)\n",
    "sns.distplot(y_p_train-y_train_log.SalePrice, axlabel='error on training set')\n",
    "plt.subplot(1,2,2)\n",
    "sns.distplot(y_p_val-y_val_log.SalePrice, axlabel='error on validation set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_val_log.SalePrice.to_numpy()\n",
    "y = y.reshape(y.shape[0])\n",
    "print(y_p_train.shape)\n",
    "df = DataFrame(data={'value':np.exp(y), 'predicted':np.exp(y_p_val)},index=y_val_log.index)\n",
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(x='value',y='predicted', data=df )\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly_idx = df['predicted'].idxmax()\n",
    "print(anomaly_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly = X_val_log.loc[anomaly_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "anomaly.loc[np.abs(anomaly)>1.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_log_scaled = model.predict(test)\n",
    "test_pred_log = scaler_Y.inverse_transform(test_pred_log_scaled)\n",
    "test_pred = np.exp(test_pred_log).reshape(test_pred.shape[0])\n",
    "\n",
    "submission = DataFrame({\"SalePrice\": test_pred}, index=test_log.index)\n",
    "submission.to_csv('test-prediction-keras-1hiddenLayer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
