{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from pandas import DataFrame, read_csv, concat, get_dummies, Series\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.metrics import mean_squared_log_error, mean_squared_error\n",
    "from sklearn.preprocessing import normalize, StandardScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost\n",
    "from xgboost import plot_importance, XGBRegressor\n",
    "from pprint import pprint\n",
    "from json import load\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "project = 'house-prices'\n",
    "version='v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fulltrain=read_csv('./train.csv',index_col=0)\n",
    "test=read_csv('./test.csv',index_col=0)\n",
    "fixed_seed=1234578416\n",
    "train80, valid20 = train_test_split(fulltrain, test_size=0.2, random_state=fixed_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = load(open('categories.json',\"r\"))\n",
    "categories.pop('OverallQual')\n",
    "categories.pop('OverallCond')\n",
    "categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#train80_qual = train80.select_dtypes(exclude=np.number)\n",
    "#valid20_qual = valid20.select_dtypes(exclude=np.number)\n",
    "#test_qual = test.select_dtypes(exclude=np.number)\n",
    "#train80 = train80.select_dtypes(include=np.number)\n",
    "#valid20 = valid20.select_dtypes(include=np.number)\n",
    "#test = test.select_dtypes(include=np.number)\n",
    "\n",
    "fields=['MoSold', 'YrSold','Utilities','MiscVal', 'PoolArea']\n",
    "\n",
    "train80.drop(fields, axis=1, inplace=True)\n",
    "valid20.drop(fields, axis=1, inplace=True)\n",
    "test.drop(fields, axis=1, inplace=True)\n",
    "\n",
    "for key in fields:\n",
    "    categories.pop(key, None)\n",
    "\n",
    "\n",
    "qual_columns = list(categories.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories['Neighborhood'][categories['Neighborhood'].index('Names')]='NAmes'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qual_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train80.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for category in categories.keys():\n",
    "    # print(categories[category])\n",
    "    train80.loc[:,category] = train80[category].astype('category',categories=categories[category])\n",
    "    valid20.loc[:,category] = valid20[category].astype('category',categories=categories[category])\n",
    "    test.loc[:,category] = test[category].astype('category',categories=categories[category])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train80 = train80.drop(train80[train80.LotArea > 200000].index)\n",
    "train80 = train80.drop(train80[train80.LotFrontage > 250].index)\n",
    "valid20 = valid20.drop(valid20[valid20.LotArea > 200000].index)\n",
    "valid20 = valid20.drop(valid20[valid20.LotFrontage > 250].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for cond in ['Abnorml','Partial']:\n",
    "    print((valid20['SaleCondition']==cond).sum())\n",
    "    print((train80['SaleCondition']==cond).sum())\n",
    "    #valid20 = valid20.drop(valid20[(valid20['SaleCondition']==cond)].index)\n",
    "    #train80 = train80.drop(train80[(train80['SaleCondition']==cond)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train80.loc[:,'SalePrice']=np.log(train80.loc[:,'SalePrice'])\n",
    "valid20.loc[:,'SalePrice']=np.log(valid20.loc[:,'SalePrice'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = {}\n",
    "mode = {}\n",
    "median ={}\n",
    "for column in list(train80.columns):\n",
    "    if column not in qual_columns:\n",
    "        mean[column]=train80[column].mean()\n",
    "        mode[column]=train80[column].mode()[0]\n",
    "        median[column]=train80[column].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price_neigh={}\n",
    "\n",
    "neighborhoods = categories['Neighborhood']\n",
    "for name in list(neighborhoods):\n",
    "    mean_price_neigh[name]=train80.loc[train80['Neighborhood']==name,'SalePrice'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column='SalePrice'\n",
    "X_train = train80.drop(target_column, axis=1)\n",
    "y_train = train80[target_column]\n",
    "X_val = valid20.drop(target_column, axis=1)\n",
    "y_val = valid20[target_column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in list(neighborhoods):\n",
    "    X_train.loc[X_train['Neighborhood']==name,'mean_price']=mean_price_neigh[name]\n",
    "    X_val.loc[X_val['Neighborhood']==name,'mean_price']=mean_price_neigh[name]\n",
    "    test.loc[test['Neighborhood']==name,'mean_price']=mean_price_neigh[name]\n",
    "X_train.loc[X_train['Neighborhood'].isna(),'mean_price']=mean['SalePrice']\n",
    "X_val.loc[X_val['Neighborhood'].isna(),'mean_price']=mean['SalePrice']\n",
    "test.loc[test['Neighborhood'].isna(),'mean_price']=mean['SalePrice']\n",
    "\n",
    "# train80_qual['Neighborhood']\n",
    "#mean_price_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_price_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, test]:\n",
    "    na_sum = df['mean_price'].isna().sum()\n",
    "    print(na_sum[na_sum!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, test]:\n",
    "    df.loc[:,'Exterior1st'] = df['Exterior1st'].fillna('VinylSd')\n",
    "    df.loc[:,'Exterior2nd'] = df['Exterior2nd'].fillna('VinylSd')\n",
    "\n",
    "    df.loc[:,'Functional'] = df['Functional'].fillna('Typ')\n",
    "    df.loc[:,'MSZoning'] = df['MSZoning'].fillna('RL')\n",
    "    df.loc[:,'SaleType'] = df['SaleType'].fillna('WD')\n",
    "#    for col in ('PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'MasVnrType'):\n",
    "#        df.loc[:,col] = df[col].fillna('None')\n",
    "#    for col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond', 'GarageType'):\n",
    "#        df.loc[:,col] = df[col].fillna('None')\n",
    "    \n",
    "    for col in ('GarageYrBlt', 'GarageArea', 'GarageCars', 'MasVnrArea'):\n",
    "        df.loc[:,col] = df[col].fillna(0)\n",
    "    \n",
    "#    for col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n",
    "#        df.loc[:,col] = df[col].fillna('None')    \n",
    "\n",
    "    for col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n",
    "        df.loc[:,col] = df[col].fillna(0)\n",
    "        \n",
    "    df.loc[:,'Electrical'] = df['Electrical'].fillna('SBrkr')\n",
    "    df.loc[:,'LotFrontage'] = df['LotFrontage'].fillna(median['LotFrontage'])\n",
    "\n",
    "    for col in ('BsmtQual', 'BsmtCond', 'FireplaceQu', 'GarageQual', 'GarageCond', 'PoolQC'):\n",
    "        df.loc[:,col] = df[col].fillna('NA')\n",
    "    for col in ('ExterQual', 'KitchenQual'):\n",
    "        df.loc[:,col] = df[col].fillna('TA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train = get_dummies(X_train, columns=qual_columns, drop_first=True)\n",
    "#X_val = get_dummies(X_val, columns=qual_columns, drop_first=True)\n",
    "#test = get_dummies(test, columns=qual_columns, drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_cols={}\n",
    "for key, value in list(categories.items()):\n",
    "    if value[0] == 'Ex':\n",
    "        ordinal_cols[key] = value\n",
    "        categories.pop(key)\n",
    "\n",
    "for col, tags in ordinal_cols.items():\n",
    "    tags.reverse()\n",
    "    for df in [X_train, X_val, test]:\n",
    "        for i, tag in enumerate(tags):\n",
    "            df.loc[ df[col]==tags[i], col+'_ord']= i\n",
    "        df.drop(col, axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for category in categories.keys():\n",
    "X_train = concat([X_train,\n",
    "                  get_dummies(X_train[list(categories.keys())])\n",
    "                 ],axis=1).drop(list(categories.keys()),axis=1)\n",
    "X_val = concat([X_val,\n",
    "                  get_dummies(X_val[list(categories.keys())])\n",
    "                 ],axis=1).drop(list(categories.keys()),axis=1)\n",
    "test = concat([test,\n",
    "                  get_dummies(test[list(categories.keys())])\n",
    "                 ],axis=1).drop(list(categories.keys()),axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(X_train.columns)\n",
    "print(X_train.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surface Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, test]:\n",
    "    # df['Surface1'] =  df['2ndFlrSF'] * 0.67918 + df['1stFlrSF'] * 0.15835 + df['TotalBsmtSF'] * 0.56624\n",
    "    # df['Surface2'] =  df['1stFlrSF'] * 0.51 + df['TotalBsmtSF'] * 0.35\n",
    "    df['Surface'] =  df['2ndFlrSF'] + df['1stFlrSF'] + df['TotalBsmtSF']\n",
    "#    df.drop('2ndFlrSF', axis=1, inplace=True)\n",
    "#    df.drop('1stFlrSF', axis=1, inplace=True)\n",
    "#    df.drop('TotalBsmtSF', axis=1, inplace=True)\n",
    "    df.drop('GrLivArea', axis=1, inplace=True)\n",
    "#    df['Garage'] = df['GarageCond'] + df['GarageFinish'] + df['GarageQual'] + df['GarageCars']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, test]:\n",
    "    na_sum = df.isna().sum()\n",
    "    print(na_sum[na_sum!=0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cols=X_train.columns[( X_train == 0).all()]\n",
    "display(zero_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [X_train, X_val, test]:\n",
    "    df.drop(columns=zero_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalization\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train[:] = scaler.transform(X_train)\n",
    "X_val[:] = scaler.transform(X_val)\n",
    "test[:] = scaler.transform(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Outliers detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = IsolationForest(max_samples=100, random_state=42, behaviour='new')\n",
    "clf.fit(X_train)\n",
    "y_pred_train = DataFrame(data=clf.predict(X_train),index=X_train.index)\n",
    "y_pred_train_str = ('C' + y_pred_train.astype('str'))[0]\n",
    "tsne = TSNE(n_components=2)\n",
    "X_tsne = tsne.fit_transform(X_train)\n",
    "plt.figure(figsize=(16,12))\n",
    "ax =sns.scatterplot(x=X_tsne[:,0], y=X_tsne[:,1], hue=y_pred_train_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isnotoutlier = (y_pred_train[0]==1)\n",
    "X_train = X_train.loc[isnotoutlier,:]\n",
    "y_train = y_train.loc[isnotoutlier]\n",
    "nb_outliers = (y_pred_train[0]==-1).sum()\n",
    "print('There was ' + str(nb_outliers) + ' outliers')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing empty columns\n",
    "\n",
    "TODO remove constant columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_cols = X_train.columns[( X_train == 0).all()]\n",
    "display(zero_cols)\n",
    "for df in [X_train, X_val, test]:\n",
    "    df.drop(columns=zero_cols, inplace=True)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gridsearch hyperparameters estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hypopt import GridSearch\n",
    "params = {'min_child_weight':[6,7,8,9], 'gamma':[i/100.0 for i in range(1,5)],  'subsample':[i/10.0 for i in range(2,5)],\n",
    "'colsample_bytree':[i/10.0 for i in range(8,10)], 'max_depth': [3,4,5]}\n",
    "\n",
    "model = XGBRegressor(booster=\"gbtree\")\n",
    "grid = GridSearch(model, params)\n",
    "grid.fit(X_train, y_train, X_val, y_val)\n",
    "grid.best_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XGBoost model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(booster=\"gbtree\",colsample_bytree=0.9,\n",
    "                     max_depth=3, n_estimators=400, gamma= 0.01,\n",
    "                     min_child_weight=6,\n",
    "                     subsample=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor(booster=\"gbtree\",colsample_bytree=0.5,\n",
    "                     max_depth=3, n_estimators=400, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RMSLE = sqrt(mean_squared_error(y_val,y_pred))\n",
    "RMSLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = DataFrame({\"SalePrice\": np.exp (test_pred)}, index=test.index)\n",
    "submission.to_csv('test-prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(y_pred-y_val)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_t_pred = model.predict(X_train)\n",
    "print(sqrt(mean_squared_error(y_train,y_t_pred)))\n",
    "sns.distplot(y_t_pred-y_train)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "Feature importance as reported by XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importance_dict = model.get_booster().get_score(importance_type=\"gain\")\n",
    "importance = DataFrame.from_dict(importance_dict, orient='index')[0].sort_values(ascending=False)\n",
    "order = list(importance.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_bars = 25\n",
    "\n",
    "plt.figure(figsize=(18,20))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "for i in range(0,2):\n",
    "    plt.subplot(4,1,i+1)\n",
    "    low = nb_bars*i\n",
    "    hi = nb_bars*(i+1)\n",
    "    bars = sns.barplot(x=importance[low:hi].index, y=importance[low:hi])\n",
    "    bars.set_xticklabels(bars.get_xticklabels(), rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reordering features by importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train[order]\n",
    "X_val = X_val[order]\n",
    "test = test[order]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save prepared datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('X_train.csv')\n",
    "X_val.to_csv('X_val.csv')\n",
    "test.to_csv('X_test.csv')\n",
    "y_train.to_csv('y_train.csv', header=True)\n",
    "y_val.to_csv('y_val.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
